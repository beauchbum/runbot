[project]
name = "llm-server"
version = "1.0.0"
description = "Local LLM inference service using FastAPI and HuggingFace transformers"
authors = [{name = "Ryan Beauchamp"}]
requires-python = ">=3.11"
dependencies = [
    "fastapi>=0.109.2",
    "uvicorn[standard]>=0.27.1",
    "pydantic>=2.6.1",
    "torch>=2.2.0",
    "transformers>=4.37.2",
    "accelerate>=0.26.1",
    "sentencepiece>=0.1.99",
    "protobuf>=4.25.2",
]

[tool.hatch.build.targets.wheel]
packages = []
